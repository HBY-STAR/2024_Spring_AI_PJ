cuda
Files already downloaded and verified
Files already downloaded and verified
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 32, 32]           1,728
       BatchNorm2d-2           [-1, 64, 32, 32]             128
            Conv2d-3           [-1, 64, 32, 32]          36,864
       BatchNorm2d-4           [-1, 64, 32, 32]             128
           Dropout-5           [-1, 64, 32, 32]               0
            Conv2d-6           [-1, 64, 32, 32]          36,864
       BatchNorm2d-7           [-1, 64, 32, 32]             128
           Dropout-8           [-1, 64, 32, 32]               0
        BasicBlock-9           [-1, 64, 32, 32]               0
           Conv2d-10           [-1, 64, 32, 32]          36,864
      BatchNorm2d-11           [-1, 64, 32, 32]             128
          Dropout-12           [-1, 64, 32, 32]               0
           Conv2d-13           [-1, 64, 32, 32]          36,864
      BatchNorm2d-14           [-1, 64, 32, 32]             128
          Dropout-15           [-1, 64, 32, 32]               0
       BasicBlock-16           [-1, 64, 32, 32]               0
           Conv2d-17          [-1, 128, 16, 16]          73,728
      BatchNorm2d-18          [-1, 128, 16, 16]             256
          Dropout-19          [-1, 128, 16, 16]               0
           Conv2d-20          [-1, 128, 16, 16]         147,456
      BatchNorm2d-21          [-1, 128, 16, 16]             256
          Dropout-22          [-1, 128, 16, 16]               0
           Conv2d-23          [-1, 128, 16, 16]           8,192
      BatchNorm2d-24          [-1, 128, 16, 16]             256
          Dropout-25          [-1, 128, 16, 16]               0
       BasicBlock-26          [-1, 128, 16, 16]               0
           Conv2d-27          [-1, 128, 16, 16]         147,456
      BatchNorm2d-28          [-1, 128, 16, 16]             256
          Dropout-29          [-1, 128, 16, 16]               0
           Conv2d-30          [-1, 128, 16, 16]         147,456
      BatchNorm2d-31          [-1, 128, 16, 16]             256
          Dropout-32          [-1, 128, 16, 16]               0
       BasicBlock-33          [-1, 128, 16, 16]               0
           Conv2d-34            [-1, 256, 8, 8]         294,912
      BatchNorm2d-35            [-1, 256, 8, 8]             512
          Dropout-36            [-1, 256, 8, 8]               0
           Conv2d-37            [-1, 256, 8, 8]         589,824
      BatchNorm2d-38            [-1, 256, 8, 8]             512
          Dropout-39            [-1, 256, 8, 8]               0
           Conv2d-40            [-1, 256, 8, 8]          32,768
      BatchNorm2d-41            [-1, 256, 8, 8]             512
          Dropout-42            [-1, 256, 8, 8]               0
       BasicBlock-43            [-1, 256, 8, 8]               0
           Conv2d-44            [-1, 256, 8, 8]         589,824
      BatchNorm2d-45            [-1, 256, 8, 8]             512
          Dropout-46            [-1, 256, 8, 8]               0
           Conv2d-47            [-1, 256, 8, 8]         589,824
      BatchNorm2d-48            [-1, 256, 8, 8]             512
          Dropout-49            [-1, 256, 8, 8]               0
       BasicBlock-50            [-1, 256, 8, 8]               0
           Conv2d-51            [-1, 512, 4, 4]       1,179,648
      BatchNorm2d-52            [-1, 512, 4, 4]           1,024
          Dropout-53            [-1, 512, 4, 4]               0
           Conv2d-54            [-1, 512, 4, 4]       2,359,296
      BatchNorm2d-55            [-1, 512, 4, 4]           1,024
          Dropout-56            [-1, 512, 4, 4]               0
           Conv2d-57            [-1, 512, 4, 4]         131,072
      BatchNorm2d-58            [-1, 512, 4, 4]           1,024
          Dropout-59            [-1, 512, 4, 4]               0
       BasicBlock-60            [-1, 512, 4, 4]               0
           Conv2d-61            [-1, 512, 4, 4]       2,359,296
      BatchNorm2d-62            [-1, 512, 4, 4]           1,024
          Dropout-63            [-1, 512, 4, 4]               0
           Conv2d-64            [-1, 512, 4, 4]       2,359,296
      BatchNorm2d-65            [-1, 512, 4, 4]           1,024
          Dropout-66            [-1, 512, 4, 4]               0
       BasicBlock-67            [-1, 512, 4, 4]               0
           Linear-68                   [-1, 10]           5,130
================================================================
Total params: 11,173,962
Trainable params: 11,173,962
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 15.44
Params size (MB): 42.63
Estimated Total Size (MB): 58.07
----------------------------------------------------------------
EPOCHS : 0

Test set: Average loss: 1.5072, Accuracy: 4561/10000 (45.61%)

EPOCHS : 1

Test set: Average loss: 1.1545, Accuracy: 5955/10000 (59.55%)

EPOCHS : 2

Test set: Average loss: 1.0070, Accuracy: 6595/10000 (65.95%)

EPOCHS : 3

Test set: Average loss: 0.8642, Accuracy: 7089/10000 (70.89%)

EPOCHS : 4

Test set: Average loss: 0.8970, Accuracy: 7099/10000 (70.99%)

EPOCHS : 5

Test set: Average loss: 0.8046, Accuracy: 7437/10000 (74.37%)

EPOCHS : 6

Test set: Average loss: 0.7081, Accuracy: 7642/10000 (76.42%)

EPOCHS : 7

Test set: Average loss: 0.5683, Accuracy: 8090/10000 (80.90%)

EPOCHS : 8

Test set: Average loss: 0.5749, Accuracy: 8083/10000 (80.83%)

EPOCHS : 9

Test set: Average loss: 0.5490, Accuracy: 8121/10000 (81.21%)

EPOCHS : 10

Test set: Average loss: 0.5854, Accuracy: 8086/10000 (80.86%)

EPOCHS : 11

Test set: Average loss: 0.5738, Accuracy: 8178/10000 (81.78%)

EPOCHS : 12

Test set: Average loss: 0.4885, Accuracy: 8424/10000 (84.24%)

EPOCHS : 13

Test set: Average loss: 0.4898, Accuracy: 8412/10000 (84.12%)

EPOCHS : 14

Test set: Average loss: 0.4632, Accuracy: 8492/10000 (84.92%)

EPOCHS : 15

Test set: Average loss: 0.4362, Accuracy: 8568/10000 (85.68%)

EPOCHS : 16

Test set: Average loss: 0.3826, Accuracy: 8723/10000 (87.23%)

EPOCHS : 17

Test set: Average loss: 0.3799, Accuracy: 8726/10000 (87.26%)

EPOCHS : 18

Test set: Average loss: 0.3756, Accuracy: 8753/10000 (87.53%)

EPOCHS : 19

Test set: Average loss: 0.3814, Accuracy: 8741/10000 (87.41%)

EPOCHS : 20

Test set: Average loss: 0.3737, Accuracy: 8759/10000 (87.59%)

EPOCHS : 21

Test set: Average loss: 0.3702, Accuracy: 8768/10000 (87.68%)

EPOCHS : 22

Test set: Average loss: 0.3707, Accuracy: 8780/10000 (87.80%)

EPOCHS : 23

Test set: Average loss: 0.3739, Accuracy: 8767/10000 (87.67%)

EPOCHS : 24

Test set: Average loss: 0.3746, Accuracy: 8770/10000 (87.70%)

EPOCHS : 25

Test set: Average loss: 0.3716, Accuracy: 8775/10000 (87.75%)

EPOCHS : 26

Test set: Average loss: 0.3718, Accuracy: 8769/10000 (87.69%)

EPOCHS : 27

Test set: Average loss: 0.3705, Accuracy: 8781/10000 (87.81%)

EPOCHS : 28

Test set: Average loss: 0.3724, Accuracy: 8775/10000 (87.75%)

EPOCHS : 29

Test set: Average loss: 0.3713, Accuracy: 8774/10000 (87.74%)

EPOCHS : 30

Test set: Average loss: 0.3718, Accuracy: 8775/10000 (87.75%)

EPOCHS : 31

Test set: Average loss: 0.3731, Accuracy: 8768/10000 (87.68%)

EPOCHS : 32

Test set: Average loss: 0.3720, Accuracy: 8776/10000 (87.76%)

EPOCHS : 33

Test set: Average loss: 0.3729, Accuracy: 8771/10000 (87.71%)

EPOCHS : 34

Test set: Average loss: 0.3716, Accuracy: 8778/10000 (87.78%)

EPOCHS : 35

Test set: Average loss: 0.3709, Accuracy: 8778/10000 (87.78%)

EPOCHS : 36

Test set: Average loss: 0.3719, Accuracy: 8774/10000 (87.74%)

EPOCHS : 37

Test set: Average loss: 0.3731, Accuracy: 8769/10000 (87.69%)

EPOCHS : 38

Test set: Average loss: 0.3718, Accuracy: 8773/10000 (87.73%)

EPOCHS : 39

Test set: Average loss: 0.3714, Accuracy: 8779/10000 (87.79%)

